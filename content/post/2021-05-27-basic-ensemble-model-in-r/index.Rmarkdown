---
title: 'Basic Ensemble Model in R'
author: Lucas Forrest
date: '2021-03/13'
slug: basic-ensemble-model-in-r
categories: [coding, data science]
tags: [coding, r, data science]
subtitle: ''
summary: ''
authors: []
lastmod: '2021-03-13T14:11:03-07:00'
featured: no
image:
caption: ''
focal_point: ''
preview_only: no
projects: []
---

## Overview

This project was designed to showcase the Ensemble Methodology for classification. Ensembles can provide better predictive capabilities than individual classification techniques; however, they come at the expense of increased processing power and time requirements. This is a proof of concept model that does not split the data into training and testing sets. 


## Library Necessary Packages

```{r}

library(mlbench)        # Dataset

library(e1071)          # SVM, NB models
library(nnet)           # Neural Net model
library(rpart)          # RPart, LOOCV models
library(MASS)           # QDA model 
library(klaR)           # RDA model 
library(randomForest)   # Random Forest model
library(caret)          # Confusion Matrix

library(ggplot2)        # Better Plots
library(rpart.plot)     # Better RPart Plots
library(wesanderson)    # Better Color Schemes

```

## Load Data 

This section imports the Breast Cancer dataset, omitting NA rows and removing the ID column, while keeping a copy of the IDs so they can be appended to the results table. 

```{r}

data(BreastCancer)
BreastCancer <- na.omit(BreastCancer) 

BreastCancer.id <- BreastCancer[, 1]

BreastCancer <- BreastCancer[,-1]

```

## Models

This section runs a variety of different classification models all which return a true or false classification. 

### Support Vector Machine Model

```{r}
mysvm <- svm(Class ~ . , BreastCancer)
mysvm.pred <- predict(mysvm, BreastCancer)

length(mysvm.pred)
length(BreastCancer$Class)

table(mysvm.pred, BreastCancer$Class)

```

### Naive Bayes Model

```{r, warning=FALSE}

mynb <- NaiveBayes(Class ~ . , BreastCancer)
mynb.pred <- predict(mynb, BreastCancer)
table(mynb.pred$class, BreastCancer$Class)

```

### Neural Net Model

```{r}

mynnet <- nnet(Class ~ . , BreastCancer, size = 1)
mynnet.pred <- predict(mynnet, BreastCancer, type = "class")
table(mynnet.pred, BreastCancer$Class)

```

### Decision Tree Model

```{r}

mytree <- rpart(Class ~ . , BreastCancer)
rpart.plot(mytree, box.palette = "GnRd")

mytree.pred <- predict(mytree, BreastCancer, type = "class")
table(mytree.pred, BreastCancer$Class)

```

### Leave-1-Out Cross Validation (LOOCV) Model

```{r}

ans <- numeric(length(BreastCancer[, 1]))

for (i in 1:length(BreastCancer[, 1])) {
 myloocv <- rpart(Class ~ . , BreastCancer[-i, ])
 myloocv.pred <- predict(myloocv, BreastCancer[i, ], type = "class", se.fit = FALSE)
 ans[i] <- myloocv.pred
}

myloocv.pred <- factor(ans, labels = levels(BreastCancer$Class))
table(myloocv.pred, BreastCancer$Class)

```

### Quadratic Discriminant Analysis Model

```{r}

BreastCancer.num <- BreastCancer

for(c in 1:ncol(BreastCancer.num)){
  BreastCancer.num[, c] <- cbind(as.numeric(BreastCancer.num[, c]))
}

myqda <- qda(Class ~ . , BreastCancer.num)
myqda.pred <- predict(myqda, BreastCancer.num)

table(myqda.pred$class, BreastCancer.num$Class)

```

### Regularized Discriminant Analysis Model

```{r}

myrda <- rda(Class ~ . , BreastCancer)
myrda.pred <- predict(myrda, BreastCancer)

table(myrda.pred$class, BreastCancer$Class)

```

### Random Forests Model

```{r}

myrf <- randomForest(Class ~ . , BreastCancer)
myrf.pred <- predict(myrf, BreastCancer)
table(myrf.pred, BreastCancer$Class)

```

## Aggregate Predictions

This section combines predictions from all other sections into one dataframe. It then converts all columns to numeric to allow for a Majority Rule column to be created. This column calculates the average of each row's values, then assigns a 1 or 2 based on whether the value is above or below 1.5. In the event of a tie (4 models with 1, 4 models with 2) the calculation takes the conservative approach of classifying as malignant. 

```{r}

Predictions.num <- data.frame(mysvm.pred, mynb.pred$class, as.factor(mynnet.pred), mytree.pred, myloocv.pred, myqda.pred$class, myrda.pred$class, myrf.pred)

for(c in 1:ncol(Predictions.num)){
  Predictions.num[, c] <- as.numeric(Predictions.num[, c])
}

denom <- ncol(Predictions.num)

Predictions.num$MajRule <- ifelse(rowSums(Predictions.num) / denom < 1.5, 1, 2)

```

## Output

This section converts the predictions back to factors, assigns names to each column of the Predictions dataframe, and creates a barchart with a count of each model's predictions. Finally, a results dataframe is created that has the ID of the sample, and the majority prediction. 

```{r}

Predictions <- Predictions.num

prednames <- c("SVM", "Naive Bayes", "Neural Net", "Decision Tree", "LOOCV", "QDA", "RDA", "Random Forest", "Majority Vote")
type <- c("benign", "malignant")

for(c in 1:ncol(Predictions)){
  names(Predictions)[c] <- prednames[c]
  Predictions[, c] <- as.factor(Predictions[, c])
  levels(Predictions[, c]) <- type
  
  print(ggplot(data = Predictions, 
               aes(x = Predictions[, c],
                   fill = Predictions[, c])) +
    geom_bar(width = 0.25) +
    scale_fill_manual(values = wes_palette(n = 3, name = "Royal1"), name = "Prediction") +
    xlab(paste("Model Type: ", 
               prednames[c])) +
    geom_text(stat = 'count', 
              aes(label = ..count..), 
              vjust = -0.4,
              hjust = NA))
}

Results <- data.frame(BreastCancer.id, Predictions$`Majority Vote`)

confusionMatrix(Predictions$`Majority Vote`, BreastCancer$Class)

```